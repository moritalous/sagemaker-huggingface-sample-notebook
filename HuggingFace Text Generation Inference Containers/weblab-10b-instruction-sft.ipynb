{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Faceで公開されている大規模言語モデルをSageMakerにデプロイ\n",
    "\n",
    "\n",
    "* 対象モデル\n",
    "  \n",
    "  matsuo-lab/weblab-10b-instruction-sft\n",
    "  \n",
    "  https://huggingface.co/matsuo-lab/weblab-10b-instruction-sft\n",
    "\n",
    "* HuggingFace Text Generation Inference Containers\n",
    "\n",
    "  https://huggingface.co/blog/sagemaker-huggingface-llm\n",
    "\n",
    "  https://aws.amazon.com/jp/blogs/machine-learning/announcing-the-launch-of-new-hugging-face-llm-inference-containers-on-amazon-sagemaker/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMakerライブラリーのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメーターを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'matsuo-lab/weblab-10b-instruction-sft'\n",
    "instance_type = 'ml.g5.12xlarge'\n",
    "gpus = '2'  # ml.g5.12xlargeのGPUは4つですが、２を指定する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAMロールの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole_name = 'AmazonSageMaker-ExecutionRole-20230617T201891' # Role name with `AmazonSageMakerFullAccess` policy attached\n",
    "\trole = iam.get_role(RoleName=role_name)['Role']['Arn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMakerへデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "image_uri = get_huggingface_llm_image_uri(\n",
    "  backend='huggingface', # or lmi\n",
    "  # region=region\n",
    ")\n",
    "\n",
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\n",
    "  'HF_MODEL_ID': model_id, # model_id from hf.co/models\n",
    "  'HF_TASK':'text-generation',          # NLP task you want to use for predictions\n",
    "  # 'HF_MODEL_QUANTIZE':'bitsandbytes',\n",
    "  'SM_NUM_GPUS': gpus,\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "  env=hub,                            # configuration for loading model from Hub\n",
    "  role=role,                          # IAM role with permissions to create an endpoint\n",
    "  image_uri=image_uri\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=600,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"大規模言語モデルについて説明してください。\"\n",
    "text = f'以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n{text}\\n\\n### 応答:'\n",
    "\n",
    "data = {\n",
    "   'inputs': text,\n",
    "   'parameters': {\n",
    "        'max_new_tokens': 100,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.95  \n",
    "   }\n",
    "}\n",
    "\n",
    "# request\n",
    "result = predictor.predict(data)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エンドポイントの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=False)\n",
    "predictor.delete_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
