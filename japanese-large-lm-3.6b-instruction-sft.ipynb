{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Faceで公開されている大規模言語モデルをSageMakerにデプロイ\n",
    "\n",
    "\n",
    "* 対象モデル\n",
    "  \n",
    "  line-corporation/japanese-large-lm-3.6b-instruction-sft\n",
    "  \n",
    "  https://huggingface.co/line-corporation/japanese-large-lm-3.6b-instruction-sft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMakerライブラリーのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAMロールの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole_name = 'AmazonSageMaker-ExecutionRole' # Role name with `AmazonSageMakerFullAccess` policy attached\n",
    "\trole = iam.get_role(RoleName=role_name)['Role']['Arn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル名などのパラメーターを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'line-corporation/japanese-large-lm-3.6b-instruction-sft'\n",
    "instance_type = 'ml.g5.2xlarge'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMakerへデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\n",
    "  'HF_MODEL_ID': model_id, # model_id from hf.co/models\n",
    "  'HF_TASK':'text-generation'          # NLP task you want to use for predictions\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "  env=hub,                            # configuration for loading model from Hub\n",
    "  role=role,                          # IAM role with permissions to create an endpoint\n",
    "  transformers_version='4.26',        # Transformers version used\n",
    "  pytorch_version='1.13',             # PyTorch version used\n",
    "  py_version='py39',                  # Python version used\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "\n",
    "input_text = '''四国の県名を全て列挙してください。'''\n",
    "\n",
    "data = {\n",
    "   'inputs': f'ユーザー: {input_text}\\nシステム: ',\n",
    "   'parameters': {\n",
    "      'max_length': 1024,\n",
    "      'do_sample': True,\n",
    "      'temperature': 0.7,\n",
    "      'top_p': 0.9,\n",
    "      'top_k': 0,\n",
    "      'repetition_penalty': 1.1,\n",
    "      'num_beams': 1,\n",
    "      'pad_token_id' : tokenizer.pad_token_id,\n",
    "      'num_return_sequences': 1,    \n",
    "   }\n",
    "}\n",
    "\n",
    "# request\n",
    "result = predictor.predict(data)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エンドポイントの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=False)\n",
    "predictor.delete_model()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
